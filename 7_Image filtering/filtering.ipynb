{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy\n",
    "import os\n",
    "#os.environ['QT_QPA_PLATFORM'] = 'xcb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREVIEW = 0 #Raw camera feed\n",
    "BLUR = 1 #Blur the filter\n",
    "FEATURES = 2 #corner detection\n",
    "CANNY = 3 #apply canny edge detector filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In image processing, \"corners\" refer to points where the intensity changes sharply in multiple directions. These are often found at:\n",
    "\n",
    "1. The intersection of two edges (e.g., corners of objects in an image).\n",
    "2. High-contrast texture points (e.g., checkerboard patterns, text edges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_params = dict(maxCorners = 500, qualityLevel = 0.2, minDistance = 15, blockSize = 9)\n",
    "#maxCorners = 500: Detect up to 500 corners.\n",
    "#qualityLevel = 0.2: Minimum quality of corners (higher means fewer but stronger corners).\n",
    "#minDistance = 15: Minimum distance between detected corners.\n",
    "#blockSize = 9: Size of the neighborhood for corner detection.\n",
    "s = 0\n",
    "\n",
    "if len(sys.argv) > 1:\n",
    "    s = sys.argv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@60.130] global cap_gstreamer.cpp:1436 open OpenCV | GStreamer warning: Error opening bin: syntax error\n",
      "[ WARN:0@60.130] global cap_gstreamer.cpp:1173 isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "image_filter = PREVIEW\n",
    "alive = True\n",
    "\n",
    "win_name = 'Camera Filters'\n",
    "cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)\n",
    "result = None\n",
    "\n",
    "source = cv2.VideoCapture(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A video is essentially a sequence of images (frames) displayed rapidly, typically at 30 or 60 frames per second (FPS).\n",
    "\n",
    "In your code, the loop continuously:\n",
    "\n",
    "1. Captures a single image (frame) from the video source.\n",
    "2. Processes it (flipping, filtering, etc.).\n",
    "3. Displays it in real-time.\n",
    "4. Repeats the process, creating the illusion of motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After videocapture, we read the capture frame by frame\n",
    "while alive:\n",
    "    has_frame, frame = source.read()\n",
    "    #has_frame is True if a frame is successfully captured.\n",
    "    #frame contains the image data\n",
    "    if not has_frame:\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    if image_filter == PREVIEW: #Shows original image\n",
    "        result = frame\n",
    "    elif image_filter == CANNY: #Applies a canny edge detector filter. Detects edges by finding areas of strong intensity changes\n",
    "        result = cv2.Canny(frame, 80, 150)\n",
    "    elif image_filter == BLUR:\n",
    "        result = cv2.blur(frame, (13, 13)) #Applies a blur effect. Smoothens image to reduce noise\n",
    "    elif image_filter == FEATURES:\n",
    "        result = frame\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #Converts the frame to grayscale (because corner detection works on intensity, not color).\n",
    "        corners = cv2.goodFeaturesToTrack(frame_gray, **feature_params) #Detects corners using goodFeaturesToTrack function\n",
    "        if corners is not None: #If corners are found, it loops through them and draws green circles around them.\n",
    "            for x, y in numpy.float32(corners).reshape(-1, 2):\n",
    "                cv2.circle(result, (int(x), int(y)), 10, (0, 255, 0), 1)\n",
    "\n",
    "    cv2.imshow(win_name, result)\n",
    "\n",
    "    key = cv2.waitKey(1) #Keeps window responsive, Without it, the OpenCV window may freeze.\n",
    "    #waits for a key to be pressed for 1ms\n",
    "    if key == ord(\"Q\") or key == ord(\"q\") or key == 27:\n",
    "        alive = False\n",
    "    elif key == ord(\"C\") or key == ord(\"c\"): #ord() gets the ASCII value of the key\n",
    "        image_filter = CANNY\n",
    "    elif key == ord(\"B\") or key == ord(\"b\"):\n",
    "        image_filter = BLUR\n",
    "    elif key == ord(\"F\") or key == ord(\"f\"):\n",
    "        image_filter = FEATURES\n",
    "    elif key == ord(\"P\") or key == ord(\"p\"):\n",
    "        image_filter = PREVIEW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "source.release()\n",
    "cv2.destroyWindow(win_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Michael",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
